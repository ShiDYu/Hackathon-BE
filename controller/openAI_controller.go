package controller

import (
	"api/model"
	"bytes"
	"encoding/json"
	"fmt"
	"io"
	"log"
	"net/http"
	"os"
	"strings"
)

const OPENAI_API_URL = "https://api.openai.com/v1/chat/completions"

func GenerateTweetHandler(w http.ResponseWriter, r *http.Request) {
	//log.Println("GenerateTweetHandler called") // ログ出力の追加

	var requestData struct {
		Prompt string `json:"prompt"`
	}

	err := json.NewDecoder(r.Body).Decode(&requestData)
	if err != nil {
		log.Printf("Error decoding request payload: %v", err)
		http.Error(w, "Invalid request payload", http.StatusBadRequest)
		return
	}
	//log.Printf("Request data: %+v", requestData)

	openAIRequest := model.OpenAIRequest{
		Model:     "gpt-3.5-turbo",
		Messages:  []model.OpenAIMessage{{Role: "user", Content: requestData.Prompt}},
		MaxTokens: 200,
		Stream:    false,
	}

	requestBody, err := json.Marshal(openAIRequest)
	if err != nil {
		log.Printf("Error marshaling OpenAI request: %v", err)
		http.Error(w, "Failed to create request to OpenAI", http.StatusInternalServerError)
		return
	}
	//log.Printf("OpenAI request body: %s", requestBody)

	req, err := http.NewRequest("POST", OPENAI_API_URL, bytes.NewBuffer(requestBody))
	if err != nil {
		log.Printf("Error creating new request: %v", err)
		http.Error(w, "Failed to create request to OpenAI", http.StatusInternalServerError)
		return
	}

	apiKey := os.Getenv("OPENAI_API_KEY")
	if apiKey == "" {
		log.Println("OpenAI API key is missing")
		http.Error(w, "OpenAI API key is missing", http.StatusInternalServerError)
		return
	}
	//log.Printf("Using OpenAI API key: %s", apiKey) // ログ出力の追加

	req.Header.Set("Content-Type", "application/json")
	req.Header.Set("Authorization", "Bearer "+apiKey)

	client := &http.Client{}
	resp, err := client.Do(req)
	if err != nil {
		log.Printf("Error making request to OpenAI: %v", err)
		http.Error(w, "Failed to get response from OpenAI", http.StatusInternalServerError)
		return
	}
	defer resp.Body.Close()

	//log.Printf("OpenAI response status: %s", resp.Status)
	if resp.StatusCode != http.StatusOK {
		body, _ := io.ReadAll(resp.Body)
		log.Printf("OpenAI API error: %s", body)
		http.Error(w, fmt.Sprintf("OpenAI API error: %s", body), http.StatusInternalServerError)
		return
	}

	var openAIResponse model.OpenAIResponse
	err = json.NewDecoder(resp.Body).Decode(&openAIResponse)
	if err != nil {
		log.Printf("Error decoding OpenAI response: %v", err)
		http.Error(w, "Failed to decode OpenAI response", http.StatusInternalServerError)
		return
	}
	//log.Printf("OpenAI response: %+v", openAIResponse)

	if len(openAIResponse.Choices) == 0 {
		log.Printf("No choices found in OpenAI response")
		http.Error(w, "No content generated by OpenAI", http.StatusInternalServerError)
		return
	}

	responseData := struct {
		Content string `json:"content"`
	}{
		Content: strings.Trim(openAIResponse.Choices[0].Message.Content, `"`),
	}

	w.Header().Set("Content-Type", "application/json")
	err = json.NewEncoder(w).Encode(responseData)
	if err != nil {
		log.Printf("Error encoding response: %v", err)
		http.Error(w, "Failed to encode response", http.StatusInternalServerError)
	}
}
